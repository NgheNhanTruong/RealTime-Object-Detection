{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'object_detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11924\\4150723963.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotos\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpipeline_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtext_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'"
     ]
    }
   ],
   "source": [
    "WORKSPACE_PATH = 'Tensorflow/workspace'\n",
    "SCRIPTS_PATH = 'Tensorflow/scripts'\n",
    "APIMODEL_PATH = 'Tensorflow/models'\n",
    "ANNOTATION_PATH = WORKSPACE_PATH+'/annotations'\n",
    "IMAGE_PATH = WORKSPACE_PATH+'/images'\n",
    "MODEL_PATH = WORKSPACE_PATH+'/models'\n",
    "PRETRAINED_MODEL_PATH = WORKSPACE_PATH+'/pre-trained-models'\n",
    "CONFIG_PATH = MODEL_PATH+'/my_ssd_mobnet/pipeline.config'\n",
    "CHECKPOINT_PATH = MODEL_PATH+'/my_ssd_mobnet/'\n",
    "\n",
    "labels = [\n",
    "        {'name':'A', 'id':1},\n",
    "        {'name':'B', 'id':2},\n",
    "        {'name':'C', 'id':3},\n",
    "        {'name':'D', 'id':4},\n",
    "        {'name':'E', 'id':5}]\n",
    "\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "\n",
    "with open(ANNOTATION_PATH + '\\label_map.pbtxt', 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')\n",
    "\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n",
    "\n",
    "CONFIG_PATH = MODEL_PATH+'/'+CUSTOM_MODEL_NAME+'/pipeline.config'\n",
    "\n",
    "import os\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(CHECKPOINT_PATH, 'ckpt-11')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections\n",
    "\n",
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(ANNOTATION_PATH+'/label_map.pbtxt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import cv2\n",
    "\n",
    "from PyQt5 import QtCore\n",
    "from PyQt5.QtCore import pyqtSlot\n",
    "from PyQt5.QtGui import QImage,QPixmap\n",
    "from PyQt5.QtWidgets import QDialog,QApplication\n",
    "from PyQt5.uic import loadUi\n",
    "import datetime\n",
    "\n",
    "class tehseeencode(QDialog):\n",
    "    def __init__(self):\n",
    "        super(tehseeencode, self).__init__()\n",
    "        loadUi('student.ui',self)\n",
    "        self.logic=0\n",
    "        self.value=1\n",
    "        self.SHOW.clicked.connect(self.onClicked)\n",
    "\n",
    "        self.TEXT.setText(\"bam SHOW de bat webcam\")\n",
    "\n",
    "    @pyqtSlot()\n",
    "    def onClicked(self):\n",
    "        cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)  \n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        while (cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            image_np = np.array(frame)\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "            # Things to try:\n",
    "            # Flip horizontally\n",
    "            # image_np = np.fliplr(image_np).copy()\n",
    "\n",
    "            # Convert image to grayscale\n",
    "            # image_np = np.tile(\n",
    "            #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "            input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "            detections = detect_fn(input_tensor)\n",
    "\n",
    "            num_detections = int(detections.pop('num_detections'))\n",
    "            detections = {key: value[0, :num_detections].numpy()\n",
    "                          for key, value in detections.items()}\n",
    "            detections['num_detections'] = num_detections\n",
    "\n",
    "            # detection_classes should be ints.\n",
    "            detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "            label_id_offset = 1\n",
    "            image_np_with_detections = image_np.copy()\n",
    "\n",
    "            viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                        image_np_with_detections,\n",
    "                        detections['detection_boxes'],\n",
    "                        detections['detection_classes']+label_id_offset,\n",
    "                        detections['detection_scores'],\n",
    "                        category_index,\n",
    "                        use_normalized_coordinates=True,\n",
    "                        max_boxes_to_draw=5,\n",
    "                        min_score_thresh=.5,\n",
    "                        agnostic_mode=False)\n",
    "\n",
    "            self.displayImage(image_np_with_detections,1)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                cap.release()\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "    def displayImage(self,img,window=1):\n",
    "        qformat = QImage.Format_Indexed8\n",
    "\n",
    "        if len(img.shape) ==3:\n",
    "            if (img.shape[2])==4:\n",
    "                qformat=QImage.Format_RGBA8888\n",
    "\n",
    "            else:\n",
    "                qformat=QImage.Format_RGB888\n",
    "        img = QImage(img,img.shape[1],img.shape[0],qformat)\n",
    "        img =img.rgbSwapped()\n",
    "        self.imgLabel.setPixmap(QPixmap.fromImage(img))\n",
    "        self.imgLabel.setAlignment(QtCore.Qt.AlignHCenter | QtCore.Qt.AlignVCenter)\n",
    "\n",
    "app=QApplication(sys.argv)\n",
    "window = tehseeencode()\n",
    "window.show()\n",
    "try:\n",
    "    sys.exit(app.exec_())\n",
    "except:\n",
    "    print('exit')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
